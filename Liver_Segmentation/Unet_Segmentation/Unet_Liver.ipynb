{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liver Tumor Segmentation using U-Net with MONAI and PyTorch\n",
    "\n",
    "This notebook demonstrates the process of training a 3D U-Net model for liver tumor segmentation using the MONAI framework and PyTorch. The workflow includes data preparation, model training, evaluation, and visualization of results.\n",
    "\n",
    "## Table of Contents\n",
    "1. **Settings**\n",
    "   - Initial settings and configurations for the notebook.\n",
    "2. **Including Libraries**\n",
    "   - Importing necessary libraries and modules, including MONAI, PyTorch, and utility functions.\n",
    "3. **Preparation (Directories, Loss function, Optimizer, and Data)**\n",
    "   - Setting up directories, defining the loss function and optimizer, and preparing the data for training and testing.\n",
    "4. **Training**\n",
    "   - Training the U-Net model using the prepared data.\n",
    "5. **Call to Training Model Function**\n",
    "   - Executing the training function with specified parameters.\n",
    "6. **Loading Information on Optimal U-Net from Files**\n",
    "   - Loading the saved training and testing metrics from files.\n",
    "7. **Plot of Dice Score and Loss Function**\n",
    "   - Visualizing the training and testing Dice scores and loss functions.\n",
    "8. **Testing**\n",
    "   - Preparing the test dataset and defining the necessary transformations.\n",
    "9. **Inference and Visualization**\n",
    "   - Performing inference on test data and visualizing the segmentation results.\n",
    "\n",
    "This notebook provides a comprehensive guide to training and evaluating a 3D U-Net model for medical image segmentation tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "This section includes the initial settings and configurations required for the notebook, such as setting up directories and device configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including Libraries\n",
    "This section imports the necessary libraries and modules, including MONAI, PyTorch, and utility functions for data preparation, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "import torch\n",
    "from utilities import train, prepare\n",
    "\n",
    "from monai.utils import first\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    EnsureChannelFirstD,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation (Directories, Loss function, Optimizer and Data)\n",
    "This section sets up the directories, defines the loss function and optimizer, and prepares the data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = '.\\\\Data'\n",
    "model_dir = '.\\\\Results' \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
    "\n",
    "data_in = prepare(data_dir, cache=True)\n",
    "def debug_test_loader(test_loader):\n",
    "    for idx,batch in enumerate(test_loader):\n",
    "        try:\n",
    "            print(f\"Elaborazione batch {idx} completata con successo\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante l'elaborazione del batch {idx}\")\n",
    "            break\n",
    "#debug_test_loader(data_in[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "This section covers the training process of the U-Net model using the prepared data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call to training model function\n",
    "This cell executes the training function with the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=600\n",
    "train(model, data_in, loss_function, optimizer, epoch, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading of informations on optimal UNET from files (output of train function)\n",
    "This cell loads the saved training and testing metrics from files for further analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
    "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
    "test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
    "test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of Dice score and Loss function\n",
    "This cell visualizes the training and testing Dice scores and loss functions using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(\"Results\", (12, 6))\n",
    "\n",
    "# Train dice loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Train Dice Loss\")\n",
    "x = [i + 1 for i in range(len(train_loss))]\n",
    "y = train_loss\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, y, color='blue', linestyle='-', marker='o', label='Train Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Train metric DICE\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Train Metric DICE\")\n",
    "x = [i + 1 for i in range(len(train_metric))]\n",
    "y = train_metric\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"DICE\")\n",
    "plt.plot(x, y, color='green', linestyle='-', marker='o', label='Train DICE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Test dice loss\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Test Dice Loss\")\n",
    "x = [i + 1 for i in range(len(test_loss))]\n",
    "y = test_loss\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, y, color='red', linestyle='-', marker='o', label='Test Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Test metric DICE\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Test Metric DICE\")\n",
    "x = [i + 1 for i in range(len(test_metric))]\n",
    "y = test_metric\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"DICE\")\n",
    "plt.plot(x, y, color='purple', linestyle='-', marker='o', label='Test DICE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "This section prepares the test dataset and defines the necessary transformations for testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "path_test_volumes = sorted(glob(os.path.join(data_dir, \"TestVolumes_splitted\", \"*.nii.gz\")))\n",
    "path_test_segmentation = sorted(glob(os.path.join(data_dir, \"TestSegmentation_splitted\", \"*.nii.gz\")))\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "        EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
    "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
    "        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
    "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sw_batch_size = 4\n",
    "roi_size = (128, 128, 64)\n",
    "dice_scores = []\n",
    "\n",
    "test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
    "# Raggruppa i file per il prefisso comune\n",
    "grouped_files = defaultdict(list)\n",
    "for file in test_files:\n",
    "    prefix = os.path.basename(file['vol']).split('_chunk_')[0]\n",
    "    grouped_files[prefix].append(file)\n",
    "\n",
    "# Funzione per trovare il file con la maggiore label in un gruppo\n",
    "def get_file_with_max_label(group):\n",
    "    max_label_sum = -1\n",
    "    selected_file = None\n",
    "    for file in group:\n",
    "        seg = LoadImaged(keys=[\"seg\"])(file)[\"seg\"]\n",
    "        label_sum = seg.sum()\n",
    "        if label_sum > max_label_sum:\n",
    "            max_label_sum = label_sum\n",
    "            selected_file = file\n",
    "    return selected_file\n",
    "\n",
    "# Seleziona il file con la maggiore label in ogni gruppo\n",
    "selected_files = [get_file_with_max_label(group) for group in grouped_files.values()]\n",
    "\n",
    "# Crea il dataset e il dataloader con i file selezionati\n",
    "test_ds = Dataset(data=selected_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "# Esegui il test sui file selezionati\n",
    "dice_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_patient in test_loader:\n",
    "        t_volume = test_patient['vol']\n",
    "        \n",
    "        test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
    "        sigmoid_activation = Activations(sigmoid=True)\n",
    "        test_outputs = sigmoid_activation(test_outputs)\n",
    "        test_outputs = test_outputs > 0.50\n",
    "        \n",
    "        max_label_idx = torch.argmax(torch.sum(test_patient[\"seg\"][0, 0, :, :, :], dim=(0, 1)))\n",
    "        if torch.sum(test_patient[\"seg\"]) == 0:\n",
    "            continue\n",
    "        \n",
    "        x = test_outputs.detach().cpu()[0, 1, :, :, max_label_idx].float()\n",
    "        y = test_patient[\"seg\"][0, 0, :, :, max_label_idx].float()\n",
    "        intersection = (x * y).sum()\n",
    "        dice_score = 2 * intersection / (x.sum() + y.sum() + 1e-6)  # Add a small epsilon to avoid division by zero\n",
    "        if dice_score>1:\n",
    "            dice_score=1\n",
    "        #print(dice_score)\n",
    "        dice_scores.append(dice_score)\n",
    "        \n",
    "\n",
    "mean_dice_score = np.mean(dice_scores)\n",
    "print(f\"Mean Dice Score: {mean_dice_score}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dice_scores, marker='o', linestyle='-', color='b', label='Dice Score')\n",
    "plt.axhline(y=np.mean(dice_scores), color='r', linestyle='--', label='Mean Dice Score')\n",
    "plt.xlabel('Test Sample Index')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.title('Dice Scores for Test Samples')\n",
    "plt.ylim(0.5, 1.1)  # Set the lower limit of the y-axis to 0.5\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
