{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main notebook\n",
    "In this notebook we will show how to train an U-NET using MONAI and PyTorch.\n",
    "We will use the functions written in the .py files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "\n",
    "import torch\n",
    "from utilities import train, prepare\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    EnsureChannelFirstD,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation (Directories, Loss function, Optimizer and Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\.conda\\envs\\siv\\Lib\\site-packages\\monai\\utils\\deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = 'E:\\\\Task03_Liver\\\\'\n",
    "model_dir = '.\\\\Results' \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
    "\n",
    "data_in = prepare(data_dir, cache=True)\n",
    "def debug_test_loader(test_loader):\n",
    "    for idx,batch in enumerate(test_loader):\n",
    "        try:\n",
    "            print(f\"Elaborazione batch {idx} completata con successo\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante l'elaborazione del batch {idx}\")\n",
    "            break\n",
    "debug_test_loader(data_in[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call to training model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/600\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train(model, data_in, loss_function, optimizer, epoch, model_dir)\n",
      "File \u001b[1;32mc:\\Users\\alber\\Desktop\\Lung_Liver_Segmentation\\Liver_Segmentation\\Unet_Segmentation\\utilities.py:156\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_in, loss, optim, max_epochs, model_dir, test_interval, device)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_dice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_metric\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m train_epoch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m train_step\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_epoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    158\u001b[0m save_loss_train\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "epoch=600\n",
    "train(model, data_in, loss_function, optimizer, epoch, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading of informations on optimal UNET from files (output of train function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
    "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
    "test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
    "test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of Dice score and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Results\", (12, 6))\n",
    "\n",
    "# Train dice loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Train Dice Loss\")\n",
    "x = [i + 1 for i in range(len(train_loss))]\n",
    "y = train_loss\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, y, color='blue', linestyle='-', marker='o', label='Train Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Train metric DICE\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Train Metric DICE\")\n",
    "x = [i + 1 for i in range(len(train_metric))]\n",
    "y = train_metric\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"DICE\")\n",
    "plt.plot(x, y, color='green', linestyle='-', marker='o', label='Train DICE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Test dice loss\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Test Dice Loss\")\n",
    "x = [i + 1 for i in range(len(test_loss))]\n",
    "y = test_loss\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, y, color='red', linestyle='-', marker='o', label='Test Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Test metric DICE\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Test Metric DICE\")\n",
    "x = [i + 1 for i in range(len(test_metric))]\n",
    "y = test_metric\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"DICE\")\n",
    "plt.plot(x, y, color='purple', linestyle='-', marker='o', label='Test DICE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_volumes = sorted(glob(os.path.join(data_dir, \"TestVolumes_splitted\", \"*.nii.gz\")))\n",
    "path_test_segmentation = sorted(glob(os.path.join(data_dir, \"TestSegmentation_splitted\", \"*.nii.gz\")))\n",
    "test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "        EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
    "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
    "        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
    "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_batch_size = 4\n",
    "roi_size = (128, 128, 64)\n",
    "with torch.no_grad():\n",
    "    test_patient = first(test_loader)\n",
    "    t_volume = test_patient['vol']\n",
    "    \n",
    "    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
    "    sigmoid_activation = Activations(sigmoid=True)\n",
    "    test_outputs = sigmoid_activation(test_outputs)\n",
    "    test_outputs = test_outputs > 0.53\n",
    "        \n",
    "    for i in range(64):\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
